{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPopjw/gLqRpIUGAkjTdyUW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syphax/solar-data/blob/dev/nb/Clean_GMP_Solar_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook pre-processes raw downloads from https://greenmountainpower.com/account/usage and produces one cleansed file, suitable for further analysis by the `Solar Viz` notebook.\n",
        "\n",
        "To run this script, you need access to Google Drive, and you need to copy the data from https://github.com/syphax/solar-data/tree/main/data to `/My Drive/Data/Solar` (or edit the path variable in the 2nd code block to point somewhere else).\n",
        "\n",
        "_TODO: Load the data directly from the GitHub repo._\n",
        "\n"
      ],
      "metadata": {
        "id": "hm-1FB99aNTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "52wes2ObaS6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrPc62eAZ1-l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "from datetime import datetime\n",
        "import dateutil\n",
        "import pytz\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import altair as alt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can of course edit this to taste:\n",
        "\n",
        "path = '/content/drive/MyDrive/Data/Solar/'"
      ],
      "metadata": {
        "id": "J_6wRHUNgeOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will require you to click through a couple windows to \n",
        "# give permission to access your GDrive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KT_RZuhfgi5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data\n",
        "\n",
        "This script preps data that was downloaded from [Green Mountain Power's website](https://greenmountainpower.com/account/usage/).\n",
        "\n",
        "GMP has an excellent UI for reporting usage, and provides downloadable data in 15 minute increments (either CSV or Green Button XML). *Unfortunately* it only supports manual data downloads in 15 day (max) chunks. *Fortuntely* it only takes a couple minutes to download several months of data. It's just slightly too easy to bother automating for a single account.\n",
        "\n",
        "Fields in the CSV downloads are:\n",
        "* `ServiceAgreement`: Account info. Format is `Account Holder / Service / Service Acronym / Account Start Date / Account Status`\n",
        "* `IntervalStart`: Timestamp; format is `yyyy-MM-dd-hh:mm:ss`\n",
        "* `IntervalEnd`: Same, 15 minutes later. Redundant but explicit!\n",
        "* `Quantity`: Amount of electricity generated\n",
        "* `UnitOfMeasure` `kWh`. I love that they have an explicit UoM field!\n"
      ],
      "metadata": {
        "id": "dB-7UiEpavW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Data/Solar/'\n",
        "\n",
        "raw_input_files = os.path.join(path, 'UsageData*.csv')\n",
        "joined_input_file = os.path.join(path, 'full_dataset.csv')\n"
      ],
      "metadata": {
        "id": "pG8ov6U5Z-Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This should list the data files that you copied from https://github.com/syphax/solar-data/tree/main/data\n",
        "\n",
        "!ls $path "
      ],
      "metadata": {
        "id": "cjSnnjys58v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This concatenates available data files. We will need to remove possible dupes, and check for completeness.\n",
        "\n",
        "!cat $raw_input_files > $joined_input_file"
      ],
      "metadata": {
        "id": "miwNfoab58gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_energy_data_raw = pd.read_csv(joined_input_file)"
      ],
      "metadata": {
        "id": "x5SOcDl86Inz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check and Clean"
      ],
      "metadata": {
        "id": "XWGyMyeog_5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What fields are there?\n",
        "\n",
        "df_energy_data_raw.dtypes"
      ],
      "metadata": {
        "id": "uDA_67Nu6IwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a clean field for kWh values\n",
        "\n",
        "df_energy_data_raw['kWh'] = 0\n",
        "\n",
        "df_energy_data_raw['kWh'] = np.where(df_energy_data_raw['UnitOfMeasure'] == 'kWh', df_energy_data_raw['Quantity'], 0)\n",
        "df_energy_data_raw['kWh'] = df_energy_data_raw['kWh'].astype(np.float64)"
      ],
      "metadata": {
        "id": "HNq9gMc76IzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick check of values in df:\n",
        "\n",
        "df_energy_data_raw.groupby(['ServiceAgreement', 'UnitOfMeasure'], as_index=False).agg(cnt_records=('ServiceAgreement','count'), \n",
        "                                                                                      unique_dt=('IntervalStart','nunique'), \n",
        "                                                                                      kwh=('kWh','sum'))"
      ],
      "metadata": {
        "id": "iirlZiRyhGfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract service level code"
      ],
      "metadata": {
        "id": "aDBAOmOgpMA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract service level code\n",
        "\n",
        "p = re.compile('.*/.*/(.*)/.*/.*')\n",
        "\n",
        "sl = df_energy_data_raw['ServiceAgreement'].str.extract(p)\n",
        "\n",
        "df_energy_data_raw['Service'] = sl[0].str.strip()\n",
        "\n",
        "# Drop Service Agreement field, for compactness and because it contains PII\n",
        "df_energy_data_raw = df_energy_data_raw.drop(['ServiceAgreement'], axis=1)\n"
      ],
      "metadata": {
        "id": "bwBb-cfYh6lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correct timestamps\n",
        "\n",
        "The timestamps in these files appear to be in local time. I discovered this when checking for dupes, and finding extra duplicates around e.g. Nov-07-2021 at 1-2am.\n",
        "\n",
        "To ensure that the timestamps are aligned consistently, we need to adjust for DST. Otherwise, we'll see a funky offset when analyzing production by hour of day."
      ],
      "metadata": {
        "id": "p0ORz9Q6pOh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_energy_data_raw"
      ],
      "metadata": {
        "id": "yB2FqMQWSX5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to UTZ, and drop ambiguous times (occurs during \"Fall Back\" events)\n",
        "\n",
        "tz_str = 'America/New_York'\n",
        "\n",
        "df_energy_data_raw['IntervalStart_utc'] = pd.to_datetime(df_energy_data_raw['IntervalStart'], format=\"%Y-%m-%d-%H:%M:%S\", errors='coerce')\n",
        "df_energy_data_raw['IntervalStart_utc'] = df_energy_data_raw['IntervalStart_utc'].dt.tz_localize(tz_str, ambiguous='NaT').dt.tz_convert('UTC')\n",
        "\n",
        "df_energy_data_raw['IntervalEnd_utc'] = pd.to_datetime(df_energy_data_raw['IntervalEnd'], format=\"%Y-%m-%d-%H:%M:%S\", errors='coerce')\n",
        "df_energy_data_raw['IntervalEnd_utc'] = df_energy_data_raw['IntervalEnd_utc'].dt.tz_localize(tz_str, ambiguous='NaT').dt.tz_convert('UTC')\n"
      ],
      "metadata": {
        "id": "tkTiIsTmTdNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many records have ambiguous timestamps:\n",
        "# As this should be a handful of records\n",
        "\n",
        "df_ambiguous_record_summary = df_energy_data_raw[(df_energy_data_raw['IntervalStart_utc'].isnull()) |\n",
        "                   (df_energy_data_raw['IntervalEnd_utc'].isnull())].groupby('Service').agg(cnt=('Quantity','count'), kwh=('kWh','sum'))\n",
        "\n",
        "print('Initial:')\n",
        "display(df_ambiguous_record_summary)\n",
        "\n",
        "df_energy_data_raw = df_energy_data_raw[(~df_energy_data_raw['IntervalStart_utc'].isnull()) &\n",
        "                   (~df_energy_data_raw['IntervalEnd_utc'].isnull())]\n",
        "\n",
        "df_ambiguous_record_summary = df_energy_data_raw[(df_energy_data_raw['IntervalStart_utc'].isnull()) |\n",
        "                   (df_energy_data_raw['IntervalEnd_utc'].isnull())].groupby('Service').agg(cnt=('Quantity','count'), kwh=('kWh','sum'))\n",
        "\n",
        "print('After cleansing:')\n",
        "display(df_ambiguous_record_summary)\n"
      ],
      "metadata": {
        "id": "J-FjQ4O4b6Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove remaining duplicate records"
      ],
      "metadata": {
        "id": "wUkC1ErmVEYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any remaining dupes\n",
        "\n",
        "df_dupe_check = df_energy_data_raw.groupby(['Service', 'IntervalStart'], as_index=False).agg(cnt_dupes=('IntervalStart','count'))\n",
        "\n",
        "df_dupe_check = df_dupe_check[df_dupe_check['cnt_dupes'] != 1]\n",
        "\n",
        "df_dupe_records = df_energy_data_raw.merge(df_dupe_check, on=['Service', 'IntervalStart'], how='inner').sort_values(['IntervalStart', 'Service'])\n",
        "\n",
        "display(df_dupe_records)"
      ],
      "metadata": {
        "id": "u2caRy4xlYIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "\n",
        "sh0 = df_energy_data_raw.shape\n",
        "\n",
        "df_energy_data_raw = df_energy_data_raw.drop_duplicates()\n",
        "\n",
        "sh1 = df_energy_data_raw.shape\n",
        "\n",
        "cnt_dupes = sh0[0] - sh1[0]\n",
        "\n",
        "print(\"Removed {:,} duplicate entries; {:,} left.\".format(cnt_dupes, sh1[0]))"
      ],
      "metadata": {
        "id": "xb5hmY9uhNIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final cleanup"
      ],
      "metadata": {
        "id": "_91Ebh-VeHuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define timestamps in terms of local time zone:"
      ],
      "metadata": {
        "id": "B5q4t6Lhh0Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and re-order columns"
      ],
      "metadata": {
        "id": "xuTFC7Xue4LL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}